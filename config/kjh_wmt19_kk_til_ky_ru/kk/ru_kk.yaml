project_name: 'nmt_wmt19_kk_til_ky'
experiment_name: 'default_transformer'
model_path: null

vocab_dir: 'data/apply_bpe_kjh_wmt19_kk_til_ky_ru/kjh_wmt19_kk_til_ky_ru'
data_root_comb: 'data/apply_bpe_kjh_wmt19_kk_til_ky_ru/kjh_wmt19_kk_til_ky_ru'
src_language_comb: 'ru'
tgt_language_comb: 'kjh_kk_ky'

data_root: 'data/apply_bpe_kjh_wmt19_kk_til_ky_ru/wmt19_kk_ru'
src_language: 'ru'
tgt_language: 'kk'

num_pred_examples: 3

add_info: ''
min_freq: 1
batch_size: 24
num_accumulation_steps: 32
train_length: 10000000
early_stop_patience: 20
check_val_every_n_steps: 10000

device: 'cuda:1'

EMB_SIZE: 256
NHEAD: 8
FFN_HID_DIM: 256
NUM_ENCODER_LAYERS: 3
NUM_DECODER_LAYERS: 3
MAXLEN: 525


lr: 0.0001
betas:
  - 0.9
  - 0.98
eps: 1.0e-9
factor: 0.5
threshold: 0.01
patience: 10
min_lr: 1.0e-6



