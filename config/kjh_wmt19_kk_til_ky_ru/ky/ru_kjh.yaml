project_name: 'nmt_wmt19_kk_til_ky'
experiment_name: 'default_transformer'
model_path: 'experiments/nmt_wmt19_kk_til_ky/default_transformer_lang_comb_ru_kjh_kk_ky_lang_ru_ky/checkpoints/best.pt'

vocab_dir: 'data/apply_bpe_kjh_wmt19_kk_til_ky_ru/kjh_wmt19_kk_til_ky_ru'
data_root_comb: 'data/apply_bpe_kjh_wmt19_kk_til_ky_ru/kjh_wmt19_kk_til_ky_ru'
src_language_comb: 'ru'
tgt_language_comb: 'kjh_kk_ky'

data_root: 'data/apply_bpe_kjh_wmt19_kk_til_ky_ru/kjh_ru'
src_language: 'ru'
tgt_language: 'kjh'

num_pred_examples: 3

add_info: 'ru_ky'
min_freq: 1
batch_size: 24
num_accumulation_steps: 32
num_steps: 5000000
early_stop_patience: 15
check_val_every_n_steps: 10000

device: 'cuda:1'

EMB_SIZE: 256
NHEAD: 8
FFN_HID_DIM: 256
NUM_ENCODER_LAYERS: 3
NUM_DECODER_LAYERS: 3
MAXLEN: 525


lr: 0.0001
betas:
  - 0.9
  - 0.98
eps: 1.0e-9
factor: 0.5
threshold: 0.01
patience: 7
min_lr: 1.0e-6



