project_name: 'nmt_til_kk'
experiment_name: 'default_transformer'
model_path: null

vocab_dir: 'data/apply_bpe_kjh_til_kk_ru'
data_root_comb: 'data/apply_bpe_kjh_til_kk_ru/kjh_til_kk_ru'
src_language_comb: 'ru'
tgt_language_comb: 'kjh_kk'

data_root: 'data/apply_bpe_kjh_til_kk_ru/til_kk_ru'
src_language: 'ru'
tgt_language: 'kk'

num_pred_examples: 3

add_info: ''
min_freq: 1
batch_size: 8
num_accumulation_steps: 32
warmup_steps: 100000
train_length: 10000000
early_stop_patience: 10
check_val_every_n_steps: 10000

device: 'cuda:1'

EMB_SIZE: 256
NHEAD: 8
FFN_HID_DIM: 256
NUM_ENCODER_LAYERS: 3
NUM_DECODER_LAYERS: 3
MAXLEN: 900

label_smoothing: 0.1

lr: 0.0001
betas:
  - 0.9
  - 0.98
eps: 1.0e-9
factor: 0.7
threshold: 0.01
patience: 5
min_lr: 1.0e-6



